{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetectionShapes_CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEu3msC8CoqBYW/9Z0yKAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumudharam/TestProject/blob/main/ObjectDetectionShapes_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libcairo2-dev libjpeg-dev libgif-dev\n",
        "!pip install pycairo\n",
        "#import cairo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUPHCdKOev_x",
        "outputId": "507351d5-6084-462d-cb5d-6632173aef4a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu8).\n",
            "libjpeg-dev set to manually installed.\n",
            "libgif-dev is already the newest version (5.1.4-2ubuntu0.1).\n",
            "libgif-dev set to manually installed.\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  libcairo-script-interpreter2 libpixman-1-dev libxcb-shm0-dev\n",
            "Suggested packages:\n",
            "  libcairo2-doc\n",
            "The following NEW packages will be installed:\n",
            "  libcairo-script-interpreter2 libcairo2-dev libpixman-1-dev libxcb-shm0-dev\n",
            "0 upgraded, 4 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 930 kB of archives.\n",
            "After this operation, 3,986 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo-script-interpreter2 amd64 1.15.10-2ubuntu0.1 [53.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-dev amd64 0.34.0-2 [244 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shm0-dev amd64 1.13-2~ubuntu18.04 [6,684 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo2-dev amd64 1.15.10-2ubuntu0.1 [626 kB]\n",
            "Fetched 930 kB in 0s (6,291 kB/s)\n",
            "Selecting previously unselected package libcairo-script-interpreter2:amd64.\n",
            "(Reading database ... 155202 files and directories currently installed.)\n",
            "Preparing to unpack .../libcairo-script-interpreter2_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\n",
            "Preparing to unpack .../libpixman-1-dev_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-shm0-dev:amd64.\n",
            "Preparing to unpack .../libxcb-shm0-dev_1.13-2~ubuntu18.04_amd64.deb ...\n",
            "Unpacking libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Selecting previously unselected package libcairo2-dev:amd64.\n",
            "Preparing to unpack .../libcairo2-dev_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Setting up libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Setting up libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting pycairo\n",
            "  Using cached pycairo-1.21.0.tar.gz (340 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycairo\n",
            "  Building wheel for pycairo (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycairo: filename=pycairo-1.21.0-cp37-cp37m-linux_x86_64.whl size=286816 sha256=961e938531c4ba844e0dea19908ee55b78175ca147abf83ef9b83191a37a0dad\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/1e/e8/ea8e397b1bea0fcbcffad6477c5ced6550a2adc259ed400405\n",
            "Successfully built pycairo\n",
            "Installing collected packages: pycairo\n",
            "Successfully installed pycairo-1.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XUsPMcpQegFF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cairo\n",
        "from google.colab import files\n",
        "from IPython.display import SVG, display, Image\n",
        "num_imgs = 50000\n",
        "\n",
        "img_size = 32\n",
        "min_object_size = 4\n",
        "max_object_size = 16\n",
        "num_objects = 2\n",
        "\n",
        "bboxes = np.zeros((num_imgs, num_objects, 4))\n",
        "imgs = np.zeros((num_imgs, img_size, img_size, 4), dtype=np.uint8)  # format: BGRA\n",
        "shapes = np.zeros((num_imgs, num_objects), dtype=int)\n",
        "num_shapes = 3\n",
        "shape_labels = ['rectangle', 'circle', 'triangle']\n",
        "colors = np.zeros((num_imgs, num_objects), dtype=int)\n",
        "num_colors = 3\n",
        "color_labels = ['r', 'g', 'b']\n",
        "\n",
        "for i_img in range(num_imgs):\n",
        "    surface = cairo.ImageSurface.create_for_data(imgs[i_img], cairo.FORMAT_ARGB32, img_size, img_size)\n",
        "    cr = cairo.Context(surface)\n",
        "\n",
        "    # Fill background white.\n",
        "    cr.set_source_rgb(1, 1, 1)\n",
        "    cr.paint()\n",
        "    \n",
        "    # TODO: Try no overlap here.\n",
        "    # Draw random shapes.\n",
        "    for i_object in range(num_objects):\n",
        "        shape = np.random.randint(num_shapes)\n",
        "        shapes[i_img, i_object] = shape\n",
        "        if shape == 0:  # rectangle\n",
        "            w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
        "            x = np.random.randint(0, img_size - w)\n",
        "            y = np.random.randint(0, img_size - h)\n",
        "            bboxes[i_img, i_object] = [x, y, w, h]\n",
        "            cr.rectangle(x, y, w, h)            \n",
        "        elif shape == 1:  # circle   \n",
        "            r = 0.5 * np.random.randint(min_object_size, max_object_size)\n",
        "            x = np.random.randint(r, img_size - r)\n",
        "            y = np.random.randint(r, img_size - r)\n",
        "            bboxes[i_img, i_object] = [x - r, y - r, 2 * r, 2 * r]\n",
        "            cr.arc(x, y, r, 0, 2*np.pi)\n",
        "        elif shape == 2:  # triangle\n",
        "            w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
        "            x = np.random.randint(0, img_size - w)\n",
        "            y = np.random.randint(0, img_size - h)\n",
        "            bboxes[i_img, i_object] = [x, y, w, h]\n",
        "            cr.move_to(x, y)\n",
        "            cr.line_to(x+w, y)\n",
        "            cr.line_to(x+w, y+h)\n",
        "            cr.line_to(x, y)\n",
        "            cr.close_path()\n",
        "        \n",
        "        # TODO: Introduce some variation to the colors by adding a small random offset to the rgb values.\n",
        "        color = np.random.randint(num_colors)\n",
        "        colors[i_img, i_object] = color\n",
        "        max_offset = 0.3\n",
        "        r_offset, g_offset, b_offset = max_offset * 2. * (np.random.rand(3) - 0.5)\n",
        "        if color == 0:\n",
        "            cr.set_source_rgb(1-max_offset+r_offset, 0+g_offset, 0+b_offset)\n",
        "        elif color == 1:\n",
        "            cr.set_source_rgb(0+r_offset, 1-max_offset+g_offset, 0+b_offset)\n",
        "        elif color == 2:\n",
        "            cr.set_source_rgb(0+r_offset, 0-max_offset+g_offset, 1+b_offset)\n",
        "        cr.fill()\n",
        "        \n",
        "imgs = imgs[..., 2::-1]  # is BGRA, convert to RGB\n",
        "\n",
        "# surface.write_to_png('imgs/{}.png'.format(i_img))\n",
        "imgs.shape, bboxes.shape, shapes.shape, colors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjt-ecKneg7j",
        "outputId": "72be8250-ceb2-43ba-bf9d-03dae1a0656e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 2, 4), (50000, 2), (50000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 5\n",
        "plt.imshow(imgs[i], interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])\n",
        "for bbox, shape, color in zip(bboxes[i], shapes[i], colors[i]):\n",
        "    plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], ec='k', fc='none'))\n",
        "    plt.annotate(shape_labels[shape], (bbox[0], bbox[1] + bbox[3] + 0.7), color=color_labels[color], clip_on=False)\n",
        "# surface.write_to_png(\"circle.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "kP-nvjG0fovc",
        "outputId": "1dc3d48c-9946-42ed-bdfc-c2c40b5ee470"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = (imgs - 128.) / 255.\n",
        "X.shape, np.mean(X), np.std(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQvjn5wmfseR",
        "outputId": "7290cddd-faca-4c1a-e994-f26422d744af"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), 0.40534848348141306, 0.26628753851284853)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colors_onehot = np.zeros((num_imgs, num_objects, num_colors))\n",
        "for i_img in range(num_imgs):\n",
        "    for i_object in range(num_objects):\n",
        "        colors_onehot[i_img, i_object, colors[i_img, i_object]] = 1\n",
        "\n",
        "shapes_onehot = np.zeros((num_imgs, num_objects, num_shapes))\n",
        "for i_img in range(num_imgs):\n",
        "    for i_object in range(num_objects):\n",
        "        shapes_onehot[i_img, i_object, shapes[i_img, i_object]] = 1\n",
        "        \n",
        "y = np.concatenate([bboxes / img_size, shapes_onehot, colors_onehot], axis=-1).reshape(num_imgs, -1)\n",
        "y.shape, np.all(np.argmax(colors_onehot, axis=-1) == colors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5Ze52T1ftqv",
        "outputId": "f458c0d6-eff0-4697-92ff-016eb89c0950"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 20), True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = int(0.8 * num_imgs)\n",
        "train_X = X[:i]\n",
        "test_X = X[i:]\n",
        "train_y = y[:i]\n",
        "test_y = y[i:]\n",
        "test_imgs = imgs[i:]\n",
        "test_bboxes = bboxes[i:]"
      ],
      "metadata": {
        "id": "sBQ8puHOfyo8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
        "\n",
        "# Activate GPU for this, otherwise the convnet will take forever to train with Theano.\n",
        "\n",
        "# TODO: Make one run with very deep network (~10 layers).\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "\n",
        "# TODO: Maybe remove pooling bc it takes away the spatial information.\n",
        "\n",
        "model = Sequential([\n",
        "        Convolution2D(32, 6, 6, input_shape=X.shape[1:], data_format=\"channels_first\", activation='relu'), \n",
        "        MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
        "        Convolution2D(64, filter_size, filter_size, data_format=\"channels_first\", activation='relu'), \n",
        "        MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
        "        Convolution2D(128, filter_size, filter_size, data_format=\"channels_first\", activation='relu'), \n",
        "# #         MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
        "        Convolution2D(128, filter_size, filter_size, data_format=\"channels_first\", activation='relu'), \n",
        "# #         MaxPooling2D(pool_size=(pool_size, pool_size)), \n",
        "        Flatten(), \n",
        "        Dropout(0.4), \n",
        "        Dense(256, activation='relu'), \n",
        "        Dropout(0.4), \n",
        "        Dense(y.shape[-1])\n",
        "        ])\n",
        "\n",
        "model.compile('adadelta', 'mse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "mGO33qVcf18S",
        "outputId": "2fcb4bc6-ccff-4ad0-b00a-f29d05227dc4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-142789ed3420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         ])\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   2011\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2013\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_8\" (type Conv2D).\n\nNegative dimension size caused by subtracting 6 from 3 for '{{node conv2d_8/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 6, 6], use_cudnn_on_gpu=true](Placeholder, conv2d_8/Conv2D/ReadVariableOp)' with input shapes: [?,32,32,3], [6,6,32,32].\n\nCall arguments received:\n  â€¢ inputs=tf.Tensor(shape=(None, 32, 32, 3), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flip bboxes during training.\n",
        "# Note: The validation loss is always quite big here because we don't flip the bounding boxes for the validation data. \n",
        "def IOU(bbox1, bbox2):\n",
        "    '''Calculate overlap between two bounding boxes [x, y, w, h] as the area of intersection over the area of unity'''\n",
        "    x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]  # TODO: Check if its more performant if tensor elements are accessed directly below.\n",
        "    x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
        "\n",
        "    w_I = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
        "    h_I = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
        "    if w_I <= 0 or h_I <= 0:  # no overlap\n",
        "        return 0\n",
        "    I = w_I * h_I\n",
        "\n",
        "    U = w1 * h1 + w2 * h2 - I\n",
        "\n",
        "    return I / U\n",
        "\n",
        "def dist(bbox1, bbox2):\n",
        "    return np.sqrt(np.sum(np.square(bbox1[:2] - bbox2[:2])))\n",
        "\n",
        "num_epochs_flipping = 50\n",
        "num_epochs_no_flipping = 0  # has no significant effect\n",
        "\n",
        "flipped_train_y = np.array(train_y)\n",
        "flipped = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "ious_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "dists_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "mses_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "acc_shapes_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "acc_colors_epoch = np.zeros((len(train_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "\n",
        "flipped_test_y = np.array(test_y)\n",
        "flipped_test = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "ious_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "dists_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "mses_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "acc_shapes_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "acc_colors_test_epoch = np.zeros((len(test_y), num_epochs_flipping + num_epochs_no_flipping))\n",
        "\n",
        "# TODO: Calculate ious directly for all samples (using slices of the array pred_y for x, y, w, h).\n",
        "for epoch in range(num_epochs_flipping):\n",
        "    print 'Epoch', epoch\n",
        "    model.fit(train_X, flipped_train_y, nb_epoch=1, validation_data=(test_X, test_y), verbose=2)\n",
        "    pred_y = model.predict(train_X)\n",
        "\n",
        "    for sample, (pred, exp) in enumerate(zip(pred_y, flipped_train_y)):\n",
        "        \n",
        "        # TODO: Make this simpler.\n",
        "        pred = pred.reshape(num_objects, -1)\n",
        "        exp = exp.reshape(num_objects, -1)\n",
        "        \n",
        "        pred_bboxes = pred[:, :4]\n",
        "        exp_bboxes = exp[:, :4]\n",
        "        \n",
        "        ious = np.zeros((num_objects, num_objects))\n",
        "        dists = np.zeros((num_objects, num_objects))\n",
        "        mses = np.zeros((num_objects, num_objects))\n",
        "        for i, exp_bbox in enumerate(exp_bboxes):\n",
        "            for j, pred_bbox in enumerate(pred_bboxes):\n",
        "                ious[i, j] = IOU(exp_bbox, pred_bbox)\n",
        "                dists[i, j] = dist(exp_bbox, pred_bbox)\n",
        "                mses[i, j] = np.mean(np.square(exp_bbox - pred_bbox))\n",
        "                \n",
        "        new_order = np.zeros(num_objects, dtype=int)\n",
        "        \n",
        "        for i in range(num_objects):\n",
        "            # Find pred and exp bbox with maximum iou and assign them to each other (i.e. switch the positions of the exp bboxes in y).\n",
        "            ind_exp_bbox, ind_pred_bbox = np.unravel_index(ious.argmax(), ious.shape)\n",
        "            ious_epoch[sample, epoch] += ious[ind_exp_bbox, ind_pred_bbox]\n",
        "            dists_epoch[sample, epoch] += dists[ind_exp_bbox, ind_pred_bbox]\n",
        "            mses_epoch[sample, epoch] += mses[ind_exp_bbox, ind_pred_bbox]\n",
        "            ious[ind_exp_bbox] = -1  # set iou of assigned bboxes to -1, so they don't get assigned again\n",
        "            ious[:, ind_pred_bbox] = -1\n",
        "            new_order[ind_pred_bbox] = ind_exp_bbox\n",
        "        \n",
        "        flipped_train_y[sample] = exp[new_order].flatten()\n",
        "        \n",
        "        flipped[sample, epoch] = 1. - np.mean(new_order == np.arange(num_objects, dtype=int))#np.array_equal(new_order, np.arange(num_objects, dtype=int))  # TODO: Change this to reflect the number of flips.\n",
        "        ious_epoch[sample, epoch] /= num_objects\n",
        "        dists_epoch[sample, epoch] /= num_objects\n",
        "        mses_epoch[sample, epoch] /= num_objects\n",
        "        \n",
        "        acc_shapes_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4:4+num_shapes], axis=-1) == np.argmax(exp[:, 4:4+num_shapes], axis=-1))\n",
        "        acc_colors_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1) == np.argmax(exp[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1))\n",
        "\n",
        "    \n",
        "    # Calculate metrics on test data. \n",
        "    pred_test_y = model.predict(test_X)\n",
        "    # TODO: Make this simpler.\n",
        "    for sample, (pred, exp) in enumerate(zip(pred_test_y, flipped_test_y)):\n",
        "        \n",
        "        # TODO: Make this simpler.\n",
        "        pred = pred.reshape(num_objects, -1)\n",
        "        exp = exp.reshape(num_objects, -1)\n",
        "        \n",
        "        pred_bboxes = pred[:, :4]\n",
        "        exp_bboxes = exp[:, :4]\n",
        "        \n",
        "        ious = np.zeros((num_objects, num_objects))\n",
        "        dists = np.zeros((num_objects, num_objects))\n",
        "        mses = np.zeros((num_objects, num_objects))\n",
        "        for i, exp_bbox in enumerate(exp_bboxes):\n",
        "            for j, pred_bbox in enumerate(pred_bboxes):\n",
        "                ious[i, j] = IOU(exp_bbox, pred_bbox)\n",
        "                dists[i, j] = dist(exp_bbox, pred_bbox)\n",
        "                mses[i, j] = np.mean(np.square(exp_bbox - pred_bbox))\n",
        "                \n",
        "        new_order = np.zeros(num_objects, dtype=int)\n",
        "        \n",
        "        for i in range(num_objects):\n",
        "            # Find pred and exp bbox with maximum iou and assign them to each other (i.e. switch the positions of the exp bboxes in y).\n",
        "            ind_exp_bbox, ind_pred_bbox = np.unravel_index(mses.argmin(), mses.shape)\n",
        "            ious_test_epoch[sample, epoch] += ious[ind_exp_bbox, ind_pred_bbox]\n",
        "            dists_test_epoch[sample, epoch] += dists[ind_exp_bbox, ind_pred_bbox]\n",
        "            mses_test_epoch[sample, epoch] += mses[ind_exp_bbox, ind_pred_bbox]\n",
        "            mses[ind_exp_bbox] = 1000000#-1  # set iou of assigned bboxes to -1, so they don't get assigned again\n",
        "            mses[:, ind_pred_bbox] = 10000000#-1\n",
        "            new_order[ind_pred_bbox] = ind_exp_bbox\n",
        "        \n",
        "        flipped_test_y[sample] = exp[new_order].flatten()\n",
        "        \n",
        "        flipped_test[sample, epoch] = 1. - np.mean(new_order == np.arange(num_objects, dtype=int))#np.array_equal(new_order, np.arange(num_objects, dtype=int))  # TODO: Change this to reflect the number of flips.\n",
        "        ious_test_epoch[sample, epoch] /= num_objects\n",
        "        dists_test_epoch[sample, epoch] /= num_objects\n",
        "        mses_test_epoch[sample, epoch] /= num_objects\n",
        "        \n",
        "        acc_shapes_test_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4:4+num_shapes], axis=-1) == np.argmax(exp[:, 4:4+num_shapes], axis=-1))\n",
        "        acc_colors_test_epoch[sample, epoch] = np.mean(np.argmax(pred[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1) == np.argmax(exp[:, 4+num_shapes:4+num_shapes+num_colors], axis=-1))\n",
        "       \n",
        "            \n",
        "    print 'Flipped {} % of all elements'.format(np.mean(flipped[:, epoch]) * 100.)\n",
        "    print 'Mean IOU: {}'.format(np.mean(ious_epoch[:, epoch]))\n",
        "    print 'Mean dist: {}'.format(np.mean(dists_epoch[:, epoch]))\n",
        "    print 'Mean mse: {}'.format(np.mean(mses_epoch[:, epoch]))\n",
        "    print 'Accuracy shapes: {}'.format(np.mean(acc_shapes_epoch[:, epoch]))\n",
        "    print 'Accuracy colors: {}'.format(np.mean(acc_colors_epoch[:, epoch]))\n",
        "    \n",
        "    print '--------------- TEST ----------------'\n",
        "    print 'Flipped {} % of all elements'.format(np.mean(flipped_test[:, epoch]) * 100.)\n",
        "    print 'Mean IOU: {}'.format(np.mean(ious_test_epoch[:, epoch]))\n",
        "    print 'Mean dist: {}'.format(np.mean(dists_test_epoch[:, epoch]))\n",
        "    print 'Mean mse: {}'.format(np.mean(mses_test_epoch[:, epoch]))\n",
        "    print 'Accuracy shapes: {}'.format(np.mean(acc_shapes_test_epoch[:, epoch]))\n",
        "    print 'Accuracy colors: {}'.format(np.mean(acc_colors_test_epoch[:, epoch]))\n",
        "    print\n",
        "    \n",
        "# print '------------------------------------'\n",
        "# print 'Training now without flipping bboxes'\n",
        "# print '------------------------------------'\n",
        "    \n",
        "# for epoch in range(num_epochs_flipping, num_epochs_flipping + num_epochs_no_flipping):\n",
        "#     print 'Epoch', epoch\n",
        "#     model.fit(train_X, flipped_train_y, nb_epoch=1, validation_data=(test_X, test_y), verbose=2)\n",
        "#     pred_y = model.predict(train_X)\n",
        "\n",
        "#     # Calculate iou/dist, but don't flip.\n",
        "#     for sample, (pred_bboxes, exp_bboxes) in enumerate(zip(pred_y, flipped_train_y)):\n",
        "        \n",
        "#         pred_bboxes = pred_bboxes.reshape(num_objects, -1)\n",
        "#         exp_bboxes = exp_bboxes.reshape(num_objects, -1)        \n",
        "        \n",
        "#         for exp_bbox, pred_bbox in zip(exp_bboxes, pred_bboxes):\n",
        "#             ious_epoch[sample, epoch] += IOU(exp_bbox, pred_bbox)\n",
        "#             dists_epoch[sample, epoch] += dist(exp_bbox, pred_bbox)\n",
        "#             mses_epoch[sample, epoch] += np.mean(np.square(exp_bbox - pred_bbox))\n",
        "            \n",
        "#         ious_epoch[sample, epoch] /= num_objects\n",
        "#         dists_epoch[sample, epoch] /= num_objects \n",
        "#         mses_epoch[sample, epoch] /= num_objects \n",
        "            \n",
        "# #     print 'Flipped {} % of all elements'.format(np.mean(flipped[:, epoch]) * 100.)\n",
        "#     print 'Mean IOU: {}'.format(np.mean(ious_epoch[:, epoch]))\n",
        "#     print 'Mean dist: {}'.format(np.mean(dists_epoch[:, epoch]))\n",
        "#     print 'Mean mse: {}'.format(np.mean(mses_epoch[:, epoch]))\n",
        "#     print"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "zqB_tT8Yf2wE",
        "outputId": "7b42d2f6-70b5-472d-e312-243ef4c24370"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-a7a4b19bef89>\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    print 'Epoch', epoch\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('Epoch', epoch)?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.layers\n",
        "weights = model.layers[0].get_weights()[0]\n",
        "weights = weights.transpose(3, 0, 1, 2)\n",
        "print weights.shape\n",
        "# plt.imshow(weights[0] * 255. + 128., interpolation='none', origin='lower')\n",
        "print np.mean(weights[0]), np.std(weights[0]), np.min(weights[0]), np.max(weights[0])\n",
        "adj_weights = (weights * 255.) + 128.\n",
        "print np.mean(adj_weights[0]), np.std(adj_weights[0]), np.min(adj_weights[0]), np.max(adj_weights[0])\n",
        "plt.figure(figsize=(16, 8))\n",
        "for i in range(24):\n",
        "    plt.subplot(4, 6, i+1)\n",
        "    plt.imshow(adj_weights[i, :, :], interpolation='none', origin='lower', cmap='Greys')"
      ],
      "metadata": {
        "id": "s8JqlEpah7c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pcolor(flipped[:1000], cmap='Greys', vmax=1.)\n",
        "# plt.axvline(num_epochs_flipping, c='r')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training sample')"
      ],
      "metadata": {
        "id": "9M3q7AZwh99I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_ious_epoch = np.mean(ious_epoch, axis=0)\n",
        "mean_dists_epoch = np.mean(dists_epoch, axis=0)\n",
        "mean_mses_epoch = np.mean(mses_epoch, axis=0)\n",
        "plt.plot(mean_ious_epoch, label='Mean IOU')  # between predicted and assigned true bboxes\n",
        "plt.plot(mean_dists_epoch, label='Mean distance')  # relative to image size\n",
        "plt.plot(mean_mses_epoch, label='Mean mse')  # relative to image size\n",
        "plt.annotate(np.round(np.max(mean_ious_epoch), 3), (len(mean_ious_epoch)-1, mean_ious_epoch[-1]+0.03), horizontalalignment='right', color='b')\n",
        "plt.annotate(np.round(np.min(mean_dists_epoch), 3), (len(mean_dists_epoch)-1, mean_dists_epoch[-1]+0.03), horizontalalignment='right', color='g')\n",
        "plt.annotate(np.round(np.min(mean_mses_epoch), 3), (len(mean_mses_epoch)-1, mean_mses_epoch[-1]+0.03), horizontalalignment='right', color='r')\n",
        "\n",
        "# TEST.\n",
        "mean_ious_epoch = np.mean(ious_test_epoch, axis=0)\n",
        "mean_dists_epoch = np.mean(dists_test_epoch, axis=0)\n",
        "mean_mses_epoch = np.mean(mses_test_epoch, axis=0)\n",
        "plt.plot(mean_ious_epoch, 'b--')  # between predicted and assigned true bboxes\n",
        "plt.plot(mean_dists_epoch, 'g--')  # relative to image size\n",
        "plt.plot(mean_mses_epoch, 'r--')  # relative to image size\n",
        "# plt.annotate(np.round(np.max(mean_ious_epoch), 3), (len(mean_ious_epoch)-1, mean_ious_epoch[-1]+0.03), horizontalalignment='right', color='b')\n",
        "# plt.annotate(np.round(np.min(mean_dists_epoch), 3), (len(mean_dists_epoch)-1, mean_dists_epoch[-1]+0.03), horizontalalignment='right', color='g')\n",
        "# plt.annotate(np.round(np.min(mean_mses_epoch), 3), (len(mean_mses_epoch)-1, mean_mses_epoch[-1]+0.03), horizontalalignment='right', color='r')\n",
        "\n",
        "# plt.axvline(num_epochs_flipping, c='r')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylim(0, 0.6)\n",
        "\n",
        "# plt.savefig('plots/color-multiple-shapes_three-colors_bboxes.png', dpi=300)"
      ],
      "metadata": {
        "id": "W70-QrM8iBSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_acc_shapes_epoch = np.mean(acc_shapes_epoch, axis=0)\n",
        "mean_acc_colors_epoch = np.mean(acc_colors_epoch, axis=0)\n",
        "plt.plot(mean_acc_shapes_epoch, label='Accuracy shapes')  # between predicted and assigned true bboxes\n",
        "plt.plot(mean_acc_colors_epoch, label='Accuracy colors')\n",
        "plt.annotate(np.round(np.max(mean_acc_shapes_epoch), 3), (len(mean_acc_shapes_epoch)-1, mean_acc_shapes_epoch[-1]+0.03), horizontalalignment='right', color='b')\n",
        "plt.annotate(np.round(np.max(mean_acc_colors_epoch), 3), (len(mean_acc_colors_epoch)-1, mean_acc_colors_epoch[-1]+0.03), horizontalalignment='right', color='g')\n",
        "\n",
        "# TEST.\n",
        "mean_acc_shapes_epoch = np.mean(acc_shapes_test_epoch, axis=0)\n",
        "mean_acc_colors_epoch = np.mean(acc_colors_test_epoch, axis=0)\n",
        "plt.plot(mean_acc_shapes_epoch, 'b--')  # between predicted and assigned true bboxes\n",
        "plt.plot(mean_acc_colors_epoch, 'g--')\n",
        "# plt.annotate(np.round(np.max(mean_acc_shapes_epoch), 3), (len(mean_acc_shapes_epoch)-1, mean_acc_shapes_epoch[-1]+0.03), horizontalalignment='right', color='b')\n",
        "# plt.annotate(np.round(np.max(mean_acc_colors_epoch), 3), (len(mean_acc_colors_epoch)-1, mean_acc_colors_epoch[-1]+0.03), horizontalalignment='right', color='g')\n",
        "\n",
        "# plt.axvline(num_epochs_flipping, c='r')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0.5, 1)\n",
        "\n",
        "# plt.savefig('plots/color-multiple-shapes_three-colors_classification.png', dpi=300)"
      ],
      "metadata": {
        "id": "ark7i-W3iDyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y = model.predict(test_X)\n",
        "pred_y = pred_y.reshape(len(pred_y), num_objects, -1)\n",
        "pred_bboxes = pred_y[..., :4] * img_size\n",
        "pred_shapes = np.argmax(pred_y[..., 4:4+num_shapes], axis=-1).astype(int)  # take max from probabilities\n",
        "# print pred_y[..., 4+num_shapes:4+num_shapes+num_colors].shape\n",
        "# print np.argmax(pred_y[..., 5:8], axis=-1).shape\n",
        "pred_colors = np.argmax(pred_y[..., 4+num_shapes:4+num_shapes+num_colors], axis=-1).astype(int)\n",
        "pred_bboxes.shape, pred_shapes.shape, pred_colors.shape"
      ],
      "metadata": {
        "id": "rzN7TQRaiGci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "for i_subplot in range(1, 9):\n",
        "    plt.subplot(2, 4, i_subplot)\n",
        "    i = np.random.randint(len(test_X))\n",
        "    plt.imshow(test_imgs[i], interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])\n",
        "    for bbox, shape, color in zip(pred_bboxes[i], pred_shapes[i], pred_colors[i]):\n",
        "        plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], ec='k', fc='none'))\n",
        "        plt.annotate(shape_labels[shape], (bbox[0], bbox[1] + bbox[3] + 0.7), color=color_labels[color], clip_on=False, bbox={'fc': 'w', 'ec': 'none', 'pad': 1, 'alpha': 0.6})\n"
      ],
      "metadata": {
        "id": "PiXywYm8iG7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(pred_bboxes[:, :, 2]), np.std(pred_bboxes[:, :, 2])"
      ],
      "metadata": {
        "id": "Q30PFTpoiTmX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}